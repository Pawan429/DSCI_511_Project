{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topics = {\n",
    "\"Streaming\" : [\"Quibi\", \"HBO\", \"Netflix\", \"Free Documentries\", \"Free Shows\"],\n",
    "\"Exercises\" : [\"Yoga\", \"Walking\", \"Running\", \"Meditate\", \"Bicycle riding\"],\n",
    "\"HBO_Shows\" : [\"Succession\",\"True Blood\",\"The Sopranos\",\"Veep\",\"The Wire\"],\n",
    "\"Virtual_Games\" : [\"Animal Crossing: New Horizons\", \"Club Penguin\", \"Monopoly\", \"Mario Kart Tour\",\"Words With Friends\"],\n",
    "\"Cooking\" : [\"pancake\", \"pasta\", \"baking hacks\", \"bread\", \"cake\", \"cookie\"],\n",
    "\"Video_Chat_Platforms\" : [\"Google hangouts\", \"Zoom\", \"QuarantineChat\", \"HouseParty\",\"Zoom Party\"],\n",
    "\"Live_Virtual_Performance\" : [\"Billie Eilish\",\"BTS\", \"Dua Lipa\", \"Sophia Ankel\"],\n",
    "\"Cameo\" : [\"Steven Galanis\", \"Rachel Dratch\", \"Mandy Moore\", \"Restaurant Workers' Relief Fund\"],\n",
    "\"Social_Media\" : [\"Memes\", \"TikTok\", \"Instagram\"],\n",
    "\"TikTok\" : [\"airplane\",\"Hibachi grill\",\"Hooters\", \"Ciara\", \"Usher\", \"Jennifer Lopez\"],\n",
    "\"Instagram\" : [\"memes\", \"video chat\", \"makeup tutorials\", \"distance dance\", \"working_from_home\"],\n",
    "\"Tiktok_Meme\" : [\"highschool musical\", \"dance workouts\", \"solo dance\", \"themed dinners\", \"distance dance\"],\n",
    "\"Virtual_Workouts\" : [\"Gym\", \"Yoga\", \"Dancing\", \"Toning workout\", \"HIIT workout\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from datetime import datetime, timedelta\n",
    "from pytrends.request import TrendReq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "date_range = (datetime.today() - timedelta(150)).strftime('%Y-%m-%d') + \" \" + datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to iterate over a list in batches of 5 & retun a list of \"lists with 5 elements\"\n",
    "def keyword_list_creator(keyword_list):\n",
    "    new_list = []\n",
    "    for i in range(int(len(keyword_list)/5)+1):\n",
    "        new_list.append(keyword_list[i*5 : (i+1)*5])\n",
    "    return(new_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return dataframe for a keyword list of 5 elements\n",
    "def trend_df(channels):\n",
    "    \n",
    "    pytrends.build_payload(channels, cat=0,timeframe = date_range , geo='US', gprop='')\n",
    "\n",
    "    interest_over_time = pytrends.interest_over_time().drop(\"isPartial\",axis = 1)\n",
    "    rel_queries = get_google_rel_queries(pytrends.related_queries())\n",
    "    return(interest_over_time, rel_queries)\n",
    "\n",
    "#function to return dataframe for a keyword list of more than 5 elements\n",
    "def create_df(topic_name):\n",
    "    \n",
    "    keywords_list = keyword_list_creator(topic_name)\n",
    "\n",
    "    for i in range(len(keywords_list)):\n",
    "        if i ==0:\n",
    "            df, google_rel_queries = trend_df(keywords_list[i])\n",
    "        else:\n",
    "            df1, google_rel_queries_1 = trend_df(keywords_list[i])\n",
    "            df = pd.concat([df, ], axis=1)\n",
    "            google_rel_queries += google_rel_queries_1\n",
    "\n",
    "\n",
    "    return(df,google_rel_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_google_rel_queries(google_rel_queries):\n",
    "    rel_queries = []\n",
    "\n",
    "    for i in google_rel_queries.keys():\n",
    "#         print(i)\n",
    "        try :\n",
    "            rel_queries += list(google_rel_queries[i]['top'][\"query\"][:])\n",
    "        except:\n",
    "            continue        \n",
    "\n",
    "    rel_queries = list(set(rel_queries))\n",
    "    return(rel_queries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_trends_df(Virtual_Games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AZURE COGNITIVE SERVICES\n",
    "\n",
    "import requests\n",
    "from azure.cognitiveservices.search.websearch import WebSearchClient\n",
    "from azure.cognitiveservices.search.websearch.models import SafeSearch\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "\n",
    "\n",
    "subscription_key = \"865c1fcf4c99425c9892bddfe34d76ed\"\n",
    "assert subscription_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bing_results(keyword_list):\n",
    "\n",
    "    bing_rel_queries_complete_list = []\n",
    "    for i in keyword_list:\n",
    "        headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "        params = {\"q\": i, \"textDecorations\": True, \"textFormat\": \"HTML\"}\n",
    "        response = requests.get(\"https://api.cognitive.microsoft.com/bing/v7.0/search\", headers=headers, params=params)\n",
    "        response.raise_for_status()    \n",
    "        bing_rel_queries_complete_list += rel_query_preprocessing(response.json())\n",
    "        \n",
    "    return(bing_rel_queries_complete_list)\n",
    "\n",
    "\n",
    "\n",
    "def rel_query_preprocessing(bing_search_result_json):\n",
    "    \n",
    "    try:\n",
    "        raw_data = bing_search_result_json['relatedSearches']\n",
    "        jsonpath_expr = parse('$..text')\n",
    "        bing_rel_queries = [match.value for match in jsonpath_expr.find(raw_data)]\n",
    "    \n",
    "    except KeyError:\n",
    "        bing_rel_queries = []\n",
    "        \n",
    "    bing_rel_queries = list(set(bing_rel_queries))\n",
    "    \n",
    "    return(bing_rel_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_bing_results(Topics[\"Instagram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-177-ec82583557ef>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-177-ec82583557ef>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \"related_queries\" :{\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "{\"Topic Name\" :\n",
    "     {\"interest over time\" : #Dataframe\n",
    "      \"related_queries\" :{\n",
    "          \"Google\": #list\n",
    "          \"Bing\" :  #list\n",
    "      }\n",
    "     }\n",
    "            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_json(Topics):\n",
    "    final_json = {}\n",
    "    \n",
    "    for i in Topics.keys():\n",
    "        print(i)\n",
    "        final_json[i] = {}\n",
    "        final_json[i][\"related_queries\"] = {}\n",
    "        final_json[i][\"interest_over_time\"],final_json[i][\"related_queries\"][\"Google\"] = create_trends_df(i)\n",
    "        final_json[i][\"related_queries\"][\"Bing\"] = []\n",
    "\n",
    "    return(final_json)\n",
    "\n",
    "# create_final_json(Topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json = create_final_json(Topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming\n",
      "Exercises\n",
      "HBO_Shows\n",
      "Virtual_Games\n",
      "Cooking\n",
      "Video_Chat_Platforms\n",
      "Live_Virtual_Performance\n",
      "Cameo\n",
      "Social_Media\n",
      "TikTok\n",
      "Instagram\n",
      "Tiktok_Meme\n",
      "Virtual_Workouts\n"
     ]
    }
   ],
   "source": [
    "for i in Topics.keys():\n",
    "    print(i)\n",
    "    try:\n",
    "        print(create_df(i))\n",
    "    except:\n",
    "        \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
