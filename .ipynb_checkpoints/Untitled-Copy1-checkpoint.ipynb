{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topics = {\n",
    "\"Streaming\" : [\"Quibi\", \"HBO\", \"Netflix\", \"Free Documentries\", \"Free Shows\"],\n",
    "\"Exercises\" : [\"Yoga\", \"Walking\", \"Running\", \"Meditate\", \"Bicycle riding\"],\n",
    "\"HBO_Shows\" : [\"Succession\",\"True Blood\",\"The Sopranos\",\"Veep\",\"The Wire\"],\n",
    "\"Virtual_Games\" : [\"Animal Crossing: New Horizons\", \"Club Penguin\", \"Monopoly\", \"Mario Kart Tour\",\"Words With Friends\"],\n",
    "\"Cooking\" : [\"pancake\", \"pasta\", \"baking hacks\", \"bread\", \"cake\", \"cookie\"],\n",
    "\"Video_Chat_Platforms\" : [\"Google hangouts\", \"Zoom\", \"QuarantineChat\", \"HouseParty\",\"Zoom Party\"],\n",
    "\"Live_Virtual_Performance\" : [\"Billie Eilish\",\"BTS\", \"Dua Lipa\", \"Sophia Ankel\"],\n",
    "\"Cameo\" : [\"Steven Galanis\", \"Rachel Dratch\", \"Mandy Moore\", \"Restaurant Workers' Relief Fund\"],\n",
    "\"Social_Media\" : [\"Memes\", \"TikTok\", \"Instagram\"],\n",
    "\"TikTok\" : [\"airplane\",\"Hibachi grill\",\"Hooters\", \"Ciara\", \"Usher\", \"Jennifer Lopez\"],\n",
    "\"Instagram\" : [\"memes\", \"video chat\", \"makeup tutorials\", \"distance dance\", \"working_from_home\"],\n",
    "\"Tiktok_Meme\" : [\"highschool musical\", \"dance workouts\", \"solo dance\", \"themed dinners\", \"distance dance\"],\n",
    "\"Virtual_Workouts\" : [\"Gym\", \"Yoga\", \"Dancing\", \"Toning workout\", \"HIIT workout\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to iterate over a list in batches of 5 & retun a list of \"lists with 5 elements\"\n",
    "def keyword_list_creator(keyword_list):\n",
    "    new_list = []\n",
    "    for i in range(int(len(keyword_list)/5)+1):\n",
    "        new_list.append(keyword_list[i*5 : (i+1)*5])\n",
    "        \n",
    "    if len(new_list[-1]) == 0:\n",
    "        new_list = new_list[:-1]\n",
    "    \n",
    "    return(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "from datetime import datetime, timedelta\n",
    "from pytrends.request import TrendReq\n",
    "import numpy as np\n",
    "\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "date_range = (datetime.today() - timedelta(150)).strftime('%Y-%m-%d') + \" \" + datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "def int_ov_time(channels):\n",
    "    \n",
    "    pytrends.build_payload(channels, cat=0,timeframe = date_range , geo='US', gprop='')\n",
    "\n",
    "    interest_over_time = pytrends.interest_over_time().drop(\"isPartial\",axis = 1)\n",
    "    \n",
    "    return(interest_over_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(topic_name):\n",
    "    \n",
    "    keywords_list = keyword_list_creator(topic_name)\n",
    "\n",
    "    for i in range(len(keywords_list)):\n",
    "        if i ==0:\n",
    "            df = int_ov_time(keywords_list[i])\n",
    "        else:\n",
    "\n",
    "            df = pd.concat([df, int_ov_time(keywords_list[i])], axis=1)\n",
    "\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            S  t  r  e   a  m   i   n  g\n",
      "date                                    \n",
      "2019-12-31  3  3  2  3  76  4  74   8  5\n",
      "2020-01-01  2  3  2  3  76  4  74  10  5\n",
      "2020-01-02  3  3  2  4  77  4  72   9  5\n",
      "2020-01-03  3  3  2  4  77  4  72   8  5\n",
      "2020-01-04  3  3  2  3  78  4  76   8  5\n",
      "...        .. .. .. ..  .. ..  ..  .. ..\n",
      "2020-05-23  3  3  2  3  87  4  85   9  5\n",
      "2020-05-24  3  3  2  3  86  4  84   8  5\n",
      "2020-05-25  3  3  2  3  89  4  82   8  5\n",
      "2020-05-26  3  3  2  3  89  4  80   9  5\n",
      "2020-05-27  3  3  2  3  88  4  83   9  5\n",
      "\n",
      "[149 rows x 9 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert s, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5254557c9aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTopics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-6b50371cfd7a>\u001b[0m in \u001b[0;36mcreate_df\u001b[0;34m(topic_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_ov_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-c800ced8b132>\u001b[0m in \u001b[0;36mint_ov_time\u001b[0;34m(channels)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_range\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'US'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0minterest_over_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"isPartial\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36minterest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;31m# parsed as a date in pandas: use explicit insert column method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             result_df.insert(len(result_df.columns), kw,\n\u001b[0;32m--> 232\u001b[0;31m                              result_df[idx].astype('int'))\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot insert {}, already exists\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert s, already exists"
     ]
    }
   ],
   "source": [
    "for i in Topics.keys():\n",
    "    print(create_df(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AZURE COGNITIVE SERVICES\n",
    "\n",
    "import requests\n",
    "from azure.cognitiveservices.search.websearch import WebSearchClient\n",
    "from azure.cognitiveservices.search.websearch.models import SafeSearch\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "\n",
    "\n",
    "subscription_key = \"865c1fcf4c99425c9892bddfe34d76ed\"\n",
    "assert subscription_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bing_results(keyword_list):\n",
    "\n",
    "    bing_rel_queries_complete_list = []\n",
    "    for i in keyword_list:\n",
    "        headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "        params = {\"q\": i, \"textDecorations\": True, \"textFormat\": \"HTML\"}\n",
    "        response = requests.get(\"https://api.cognitive.microsoft.com/bing/v7.0/search\", headers=headers, params=params)\n",
    "        response.raise_for_status()    \n",
    "        bing_rel_queries_complete_list += rel_query_preprocessing(response.json())\n",
    "        \n",
    "    return(bing_rel_queries_complete_list)\n",
    "\n",
    "\n",
    "\n",
    "def rel_query_preprocessing(bing_search_result_json):\n",
    "    \n",
    "    try:\n",
    "        raw_data = bing_search_result_json['relatedSearches']\n",
    "        jsonpath_expr = parse('$..text')\n",
    "        bing_rel_queries = [match.value for match in jsonpath_expr.find(raw_data)]\n",
    "    \n",
    "    except KeyError:\n",
    "        bing_rel_queries = []\n",
    "        \n",
    "    bing_rel_queries = list(set(bing_rel_queries))\n",
    "    \n",
    "    return(bing_rel_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_json(Topics):\n",
    "    final_json = {}\n",
    "    \n",
    "    for i in Topics.keys():\n",
    "        print(i)\n",
    "        final_json[i] = {}\n",
    "        final_json[i][\"related_queries\"] = {}\n",
    "        final_json[i][\"interest_over_time\"],final_json[i][\"related_queries\"][\"Google\"] = create_trends_df(i)\n",
    "        final_json[i][\"related_queries\"][\"Bing\"] = []\n",
    "\n",
    "    return(final_json)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
